{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932f6838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "from random import sample\n",
    "\n",
    "from scipy.io import wavfile, savemat\n",
    "from scipy.fft import fft, fftfreq\n",
    "from scipy import signal\n",
    "from scipy.fft import fftshift\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import librosa\n",
    "import mne\n",
    "import pymatreader\n",
    "import yasa\n",
    "import seaborn as sns\n",
    "import pyxdf\n",
    "\n",
    "from mne.time_frequency import psd_array_multitaper\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from mne.decoding import CSP\n",
    "from scipy.integrate import simps\n",
    "from yasa import sliding_window\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib qt\n",
    "\n",
    "%matplotlib inline\n",
    "import plotly.io as pio\n",
    "pio.renderers.default='notebook'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8d2c39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a3826f4",
   "metadata": {},
   "source": [
    "# Steps in this notebook\n",
    "1. Filter the data [Done in EEGLAB]\n",
    "2. Single-subject ERP\n",
    "3. Grand average ERP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e10061",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/mnt/sda1/shivam/Thesis/Grasp Experiment/Data/PreprocessedData/Preprocess HAPPE\"\n",
    "exclusion = [\"FP01\", \"FP10\"]\n",
    "os.chdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccba234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = 1000\n",
    "ch_type = \"eeg\"\n",
    "nchan = 64\n",
    "channels = [f'E{n:1}' for n in range(1, nchan+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766784bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mne.channels.get_builtin_montages()\n",
    "chans = mne.channels.make_standard_montage('GSN-HydroCel-64_1.0')\n",
    "info = mne.create_info(channels, sfreq=sf, ch_types=ch_type)\n",
    "info.set_montage(chans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b06191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action_events(events):\n",
    "    new_keys_dict = {}\n",
    "    for key in events[1].keys():\n",
    "        if \"ActionBeg\" in key:\n",
    "            new_keys_dict[key] = events[1][key]\n",
    "    new_event_times = [row for row in events[0] if row[2] in new_keys_dict.values()] \n",
    "    return (new_event_times, new_keys_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2303da3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eeg_df_main = pd.DataFrame()\n",
    "\n",
    "for files in glob.glob(\"*.set\"):\n",
    "    if files[:-4] not in exclusion:\n",
    "        arr = mne.io.read_raw_eeglab(files, verbose=0)\n",
    "        eeg_data = arr.to_data_frame()\n",
    "        events = mne.events_from_annotations(arr, verbose=0)\n",
    "        \n",
    "        # Extracting events of interest\n",
    "        new_events = get_action_events(events)\n",
    "        \n",
    "        epochs = mne.Epochs(arr, new_events[0], event_id=new_events[1], tmin=-0.1, tmax=0.999,  baseline=None, verbose=0)\n",
    "        epoch_df = epochs.to_data_frame()\n",
    "        \n",
    "        n_epochs = len(np.unique(epoch_df['epoch']))\n",
    "        \n",
    "        # Transforming epoch dataframe to dataframe of interets\n",
    "        all_epochs_df = pd.DataFrame()\n",
    "        ctr = 1\n",
    "        for n_epoch in range(n_epochs):\n",
    "            eeg_only = epoch_df[epoch_df[\"epoch\"] == n_epoch].reset_index().iloc[:, 4:].T\n",
    "            label = epoch_df[epoch_df[\"epoch\"] == n_epoch][\"condition\"].iloc[0]\n",
    "            eeg_only[\"HandPos\"] = label.split(\"-\")[1]\n",
    "            eeg_only[\"Hand\"] = label.split(\"-\")[2]\n",
    "            eeg_only[\"Action\"] = label.split(\"-\")[3]\n",
    "            eeg_only[\"Subject\"] = files.split(\".\")[0]\n",
    "            eeg_only[\"Channel\"] = [x[1:] for x in eeg_only.index]\n",
    "            eeg_only[\"Trial\"] = ctr\n",
    "            eeg_only.reset_index()\n",
    "            ctr += 1\n",
    "\n",
    "            all_epochs_df = pd.concat([all_epochs_df, eeg_only])\n",
    "\n",
    "        eeg_df_main = pd.concat([eeg_df_main, all_epochs_df])\n",
    "        print(eeg_df_main.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adbd718",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_df_main = eeg_df_main.rename(columns={\"Component\": \"Channel\"})\n",
    "eeg_df_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d02c7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_df_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dffddc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(eeg_df_main, columns=list(range(1100))+[\"HandPos\", \"Hand\", \"Action\", \"Subject\", \"Channel\", \"Trial\"])\n",
    "os.chdir(\"/mnt/sda1/shivam/Thesis/Grasp Experiment/Data/CleanSep/\")\n",
    "df.to_csv(\"cleaned_data_asr.csv\", index=False, header=list(range(1100))+[\"handPos\", \"Hand\", \"Action\", \"Subject\", \"Channel\", \"Trial\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64b8d3a",
   "metadata": {},
   "source": [
    "## Save trials as MAT file as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62e3ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a48313",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjets = np.unique(dataset.Subject)\n",
    "subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f786bd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/mnt/sda1/shivam/Thesis/Grasp Experiment/Data/IntData/ASR/matv1\")\n",
    "for sub in subjects:\n",
    "    for palm in [\"palmDown\", \"palmIn\", \"palmUp\"]:\n",
    "        for oc in [\"Open\", \"Close\"]:\n",
    "            for hand in [\"Left\", \"Right\"]:\n",
    "                cond_eeg = dataset[\n",
    "                        (dataset[\"Subject\"] == sub) &\n",
    "                        (dataset[\"handPos\"] == palm) &\n",
    "                        (dataset[\"Action\"] == oc) &\n",
    "                        (dataset[\"Hand\"] == hand)\n",
    "                    ]\n",
    "                trials = np.unique(cond_eeg.Trial)\n",
    "                for trial in trials:\n",
    "                    p_eeg = cond_eeg[cond_eeg[\"Trial\"] == trial]\n",
    "                    save_name = sub+\"-\"+palm+\"-\"+hand+\"-\"+oc+\"-\"+str(trial)+\".mat\"\n",
    "                    savemat(save_name, mdict={\"EEG\": p_eeg.to_numpy() })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7173d40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1e602c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bd33290",
   "metadata": {},
   "source": [
    "# ERP Analysis\n",
    "Subject-wise average and ERP analysis\n",
    "1. Electrode-wise\n",
    "2. Average of electrodes in the ROI: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f028ada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/mnt/sda1/shivam/Thesis/Grasp Experiment/Data/CleanSep/\")\n",
    "dataset = pd.read_csv(\"cleaned_data_asr.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f52679",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(dataset.iloc[:, -2], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cfc699",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/mnt/sda1/shivam/Thesis/Grasp Experiment/Data/PreprocessedData/Preprocessedv2/\")\n",
    "arr = mne.io.read_raw_eeglab(\"P01.set\", verbose=0)\n",
    "channels = arr.ch_names#np.array([[x] for x in ])\n",
    "events = mne.events_from_annotations(arr, verbose=0)\n",
    "print(channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f694282",
   "metadata": {},
   "outputs": [],
   "source": [
    "chans.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950281fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# All subjects\n",
    "os.chdir(\"/mnt/sda1/shivam/Thesis/Grasp Experiment/Data/Plots/ASR/Subject-wise plots\")\n",
    "for sub in subjects:\n",
    "    conditions_dict = {}\n",
    "    conds_trial_ctr = {}\n",
    "    for x in events[1].keys():\n",
    "        if \"ActionBeg\" in x:\n",
    "            conditions_dict[x[10:]] = []\n",
    "            conds_trial_ctr[x[10:]] = 0\n",
    "\n",
    "    # Single subject ERP\n",
    "    conds = conditions_dict\n",
    "    cond_ctr = conds_trial_ctr\n",
    "\n",
    "    for palm in [\"palmDown\", \"palmIn\", \"palmUp\"]:\n",
    "        for oc in [\"Open\", \"Close\"]:\n",
    "            for hand in [\"Left\", \"Right\"]:\n",
    "                cond_data = dataset[(dataset[\"handPos\"] == palm) & \n",
    "                        (dataset[\"Action\"] == oc) & \n",
    "                        (dataset[\"Hand\"] == hand) & \n",
    "                        (dataset[\"Subject\"] == sub)]\n",
    "                epochs = np.unique(cond_data.iloc[:, -1])\n",
    "\n",
    "                for i in epochs:\n",
    "                    test_sub_trial = cond_data[cond_data[\"Trial\"] == i]\n",
    "                    test_sub_trial.index = test_sub_trial.iloc[:, -2]\n",
    "                    name = palm + \"-\" + hand + \"-\" + oc \n",
    "                    \n",
    "                    if test_sub_trial.shape[1] == 0:\n",
    "                        continue\n",
    "\n",
    "                    if len(conds[name]) > 0:\n",
    "                        conds[name] += test_sub_trial.iloc[:, :-6].to_numpy()\n",
    "                    else:\n",
    "                        conds[name] = test_sub_trial.iloc[:, :-6].to_numpy()\n",
    "\n",
    "                    cond_ctr[name] += 1\n",
    "    cond_avg = {}\n",
    "    for key in conds.keys():\n",
    "        cond_avg[key] = conds[key] / cond_ctr[key]\n",
    "\n",
    "    channels = np.unique(dataset[dataset[\"Subject\"] == sub].iloc[:, -2])\n",
    "\n",
    "    for key in cond_avg.keys():\n",
    "        fig = px.line(pd.DataFrame(cond_avg[key].T, columns=channels), title=sub + \"-\" + key)\n",
    "        fig.write_image(sub + \"-\" + key + \".png\") \n",
    "#         fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b4a388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average of ROI channels for subject-wise ERP\n",
    "# All subjects\n",
    "os.chdir(\"/mnt/sda1/shivam/Thesis/Grasp Experiment/Data/Plots/ASR/Subject-wise ROI\")\n",
    "for sub in subjects:\n",
    "    conditions_dict = {}\n",
    "    conds_trial_ctr = {}\n",
    "    for x in events[1].keys():\n",
    "        if \"ActionBeg\" in x:\n",
    "            conditions_dict[x[10:]] = []\n",
    "            conds_trial_ctr[x[10:]] = 0\n",
    "            \n",
    "    sub_channels = np.unique(dataset[dataset[\"Subject\"] == sub].iloc[:, -2])\n",
    "    roi_chan = list(pd.read_csv(\"/mnt/sda1/shivam/Thesis/Grasp Experiment/Data/ChannelLocations/roi-grasp-small.csv\", header=None))\n",
    "    current_roi = [x for x in sub_channels if x in roi_chan]\n",
    "    \n",
    "    # Single subject ERP\n",
    "    conds = conditions_dict\n",
    "    cond_ctr = conds_trial_ctr\n",
    "\n",
    "    for palm in [\"palmDown\", \"palmIn\", \"palmUp\"]:\n",
    "        for oc in [\"Open\", \"Close\"]:\n",
    "            for hand in [\"Left\", \"Right\"]:\n",
    "                cond_data = dataset[(dataset[\"handPos\"] == palm) & \n",
    "                        (dataset[\"Action\"] == oc) & \n",
    "                        (dataset[\"Hand\"] == hand) & \n",
    "                        (dataset[\"Subject\"] == sub)]\n",
    "                epochs = np.unique(cond_data.iloc[:, -1])\n",
    "\n",
    "                for i in epochs:\n",
    "                    test_sub_trial = cond_data[cond_data[\"Trial\"] == i]\n",
    "                    test_sub_trial.index = test_sub_trial.iloc[:, -2]\n",
    "                    name = palm + \"-\" + hand + \"-\" + oc \n",
    "                    \n",
    "                    if test_sub_trial.shape[1] == 0:\n",
    "                        continue\n",
    "\n",
    "                    if len(conds[name]) > 0:\n",
    "                        conds[name] += test_sub_trial.iloc[:, :-6].to_numpy()\n",
    "                    else:\n",
    "                        conds[name] = test_sub_trial.iloc[:, :-6].to_numpy()\n",
    "\n",
    "                    cond_ctr[name] += 1\n",
    "    cond_avg = {}\n",
    "    for key in conds.keys():\n",
    "        cond_avg[key] = conds[key] / cond_ctr[key]\n",
    "\n",
    "    cond_roi = {}\n",
    "    for key in cond_avg.keys():\n",
    "        current_roi = [x for x in sub_channels if x in roi_chan]\n",
    "        cond_roi[key] = np.mean(cond_avg[key][tuple(current_roi), :], axis=0)\n",
    "    \n",
    "    for palm in [\"palmDown\", \"palmIn\", \"palmUp\"]:\n",
    "        for hand in [\"Left\", \"Right\"]:\n",
    "            cond = palm+\"-\"+hand \n",
    "            fig = px.line(\n",
    "                pd.DataFrame(data=[cond_roi[cond+\"-Open\"], cond_roi[cond+\"-Close\"]], index=[\"Open\", \"Close\"]).T,\n",
    "                title=cond+\"-\"+sub\n",
    "            )\n",
    "            fig.write_image(cond+\"-\"+sub + \".png\") \n",
    "#             fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac24592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grand-average ERPs with ROI channels' average\n",
    "all_subj_cond = {}\n",
    "subjects = np.unique(dataset.Subject)\n",
    "os.chdir(\"/mnt/sda1/shivam/Thesis/Grasp Experiment/Data/Plots/ASR/Grand Average\")\n",
    "\n",
    "for sub in subjects:\n",
    "    conditions_dict = {}\n",
    "    conds_trial_ctr = {}\n",
    "    for x in events[1].keys():\n",
    "        if \"ActionBeg\" in x:\n",
    "            conditions_dict[x[10:]] = []\n",
    "            conds_trial_ctr[x[10:]] = 0\n",
    "    \n",
    "    sub_channels = np.unique(dataset[dataset[\"Subject\"] == sub].iloc[:, -2])\n",
    "    roi_chan = list(pd.read_csv(\"/mnt/sda1/shivam/Thesis/Grasp Experiment/Data/ChannelLocations/roi-grasp-small.csv\", header=None))\n",
    "    current_roi = [x for x in sub_channels if x in roi_chan]\n",
    "    \n",
    "    # Single subject ERP\n",
    "    conds = conditions_dict\n",
    "    cond_ctr = conds_trial_ctr\n",
    "    \n",
    "    for palm in [\"palmDown\", \"palmIn\", \"palmUp\"]:\n",
    "        for oc in [\"Open\", \"Close\"]:\n",
    "            for hand in [\"Left\", \"Right\"]:\n",
    "                cond_data = dataset[(dataset[\"handPos\"] == palm) & \n",
    "                        (dataset[\"Action\"] == oc) & \n",
    "                        (dataset[\"Hand\"] == hand) & \n",
    "                        (dataset[\"Subject\"] == sub)]\n",
    "                epochs = np.unique(cond_data.iloc[:, -1])\n",
    "\n",
    "                for i in epochs:\n",
    "                    test_sub_trial = cond_data[cond_data[\"Trial\"] == i]\n",
    "                    test_sub_trial.index = test_sub_trial.iloc[:, -2]\n",
    "                    name = palm + \"-\" + hand + \"-\" + oc \n",
    "                    \n",
    "                    if test_sub_trial.shape[1] == 0:\n",
    "                        continue\n",
    "\n",
    "                    if len(conds[name]) > 0:\n",
    "                        conds[name] += test_sub_trial.iloc[:, :-6].to_numpy()\n",
    "                    else:\n",
    "                        conds[name] = test_sub_trial.iloc[:, :-6].to_numpy()\n",
    "\n",
    "                    cond_ctr[name] += 1\n",
    "\n",
    "    cond_avg = {}\n",
    "    for key in conds.keys():\n",
    "        cond_avg[key] = conds[key] / cond_ctr[key]\n",
    "\n",
    "    cond_roi = {}\n",
    "    for key in cond_avg.keys():\n",
    "        current_roi = [x for x in sub_channels if x in roi_chan]\n",
    "        cond_roi[key] = np.mean(cond_avg[key][tuple(current_roi), :], axis=0)\n",
    "    \n",
    "    for key in cond_roi.keys():\n",
    "        if key in all_subj_cond:\n",
    "            all_subj_cond[key] += cond_roi[key] \n",
    "        else:\n",
    "            all_subj_cond[key] = cond_roi[key] \n",
    "#         print(all_subj_cond[key])\n",
    "    \n",
    "for palm in [\"palmDown\", \"palmIn\", \"palmUp\"]:\n",
    "    for hand in [\"Left\", \"Right\"]:\n",
    "        cond = palm+\"-\"+hand \n",
    "        fig = px.line(\n",
    "            pd.DataFrame(data=[cond_roi[cond+\"-Open\"], cond_roi[cond+\"-Close\"]], index=[\"Open\", \"Close\"]).T,\n",
    "            title=cond\n",
    "        )\n",
    "        fig.write_image(cond+\".png\") \n",
    "    \n",
    "        #fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b769b5",
   "metadata": {},
   "source": [
    "# Feature Extraction Methods\n",
    "1. Power spectral density [band-wise and entire band] Running...\n",
    "2. Raw data\n",
    "3. ~ICA Activation~\n",
    "4. Spectopo graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b47c098",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "1. Left vs Right\n",
    "2. In vs Up vs Down\n",
    "3. Open vs Close\n",
    "\n",
    "    3.1 Left hand and right hand\n",
    "    \n",
    "    3.2 Inwards, upwards, and downwards directions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e853ecc2",
   "metadata": {},
   "source": [
    "# Validation Techniques\n",
    "1. K-fold cross validation\n",
    "2. Predict right hand from left and right hemishpere and vice-versa\n",
    "3. Channel-wise prediction\n",
    "4. Compare classification performance on ROI vs non-ROI electrodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5842178",
   "metadata": {},
   "source": [
    "# Prediction Methods\n",
    "1. Single-subject\n",
    "\n",
    "    1.1 EEGNET\n",
    "    \n",
    "    1.2 Machine Learning\n",
    "    \n",
    "    1.3 Meta Learning\n",
    "    \n",
    "    1.4 CNN (spectopo)\n",
    "    \n",
    "    1.5 [Graph Convolutional Neural Network](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9976236)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adb80dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/mnt/sda1/shivam/Thesis/Grasp Experiment/Data/CleanSep/\")\n",
    "dataset = pd.read_csv(\"cleaned_data_asr.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059dbfb2",
   "metadata": {},
   "source": [
    "# Power Spectral Density\n",
    "1. Delta\n",
    "2. Theta\n",
    "3. Alpha\n",
    "4. Beta\n",
    "5. Gamma\n",
    "6. Entire Band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889829d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subjects = np.unique(dataset.Subject)\n",
    "X, y_oc, y_lr, y_pos, subjs = [], [], [], [], []\n",
    "grasp_labels = {\"Open\": 0, \"Close\": 1}\n",
    "hand_labels = {\"Left\": 0, \"Right\": 1}\n",
    "pos_dict = {\"palmDown\": 0, \"palmUp\": 1, \"palmIn\": 2}\n",
    "\n",
    "for sub in subjects:\n",
    "    sub_channels = np.unique(dataset[dataset[\"Subject\"] == sub].iloc[:, -2])\n",
    "    for palm in [\"palmDown\", \"palmIn\", \"palmUp\"]:\n",
    "        for oc in [\"Open\", \"Close\"]:\n",
    "            for hand in [\"Left\", \"Right\"]:\n",
    "                cond_data = dataset[(dataset[\"handPos\"] == palm) & \n",
    "                        (dataset[\"Action\"] == oc) & \n",
    "                        (dataset[\"Hand\"] == hand) & \n",
    "                        (dataset[\"Subject\"] == sub)]\n",
    "                epochs = np.unique(cond_data.iloc[:, -1])\n",
    "\n",
    "                for i in epochs:\n",
    "                    test_sub_trial = cond_data[cond_data[\"Trial\"] == i]\n",
    "                    test_sub_trial.index = test_sub_trial.iloc[:, -2]\n",
    "                     \n",
    "                    X.append(test_sub_trial.iloc[:, :-6].to_numpy())\n",
    "                    subjs.append(test_sub_trial.iloc[0, -3])\n",
    "                    y_oc.append(grasp_labels[test_sub_trial.iloc[0, -4]])\n",
    "                    y_lr.append(hand_labels[test_sub_trial.iloc[0, -5]])\n",
    "                    y_pos.append(pos_dict[test_sub_trial.iloc[0, -6]])\n",
    "\n",
    "X = np.array(X)\n",
    "y_oc = np.array(y_oc) \n",
    "y_lr = np.array(y_lr)\n",
    "y_pos = np.array(y_pos) \n",
    "subjs = np.array(subjs)\n",
    "X.shape, y_oc.shape, y_lr.shape, y_pos.shape, subjs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25381972",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9266cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multitaper method\n",
    "def bandpower_multitaper(data, sf, method, band, relative=False):\n",
    "    band = np.asarray(band)\n",
    "    low, high = band\n",
    "\n",
    "    if method == 'multitaper':\n",
    "        psd_trial, freqs = psd_array_multitaper(data, sf, adaptive=True,\n",
    "                                                normalization='full', verbose=0)\n",
    "    # Frequency resolution\n",
    "    freq_res = freqs[1] - freqs[0]\n",
    "\n",
    "    # Find index of band in frequency vector\n",
    "    idx_band = np.logical_and(freqs >= low, freqs <= high)\n",
    "\n",
    "    # Integral approximation of the spectrum using parabola (Simpson's rule)\n",
    "    bp = simps(psd_trial[idx_band], dx=freq_res)\n",
    "\n",
    "    return bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b52fbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bandpower_features(epochs, frequency):\n",
    "    bandpower_multitaper_EEG = []\n",
    "    # Iterating over each subject [20]\n",
    "    for epoch in epochs:\n",
    "        # Iterating over each song per subject [30]\n",
    "        bands_video = []\n",
    "        no_channels = epoch.shape[0]\n",
    "        input_brainwaves = epoch\n",
    "        # Iterating over each channel [14]\n",
    "        for k in range(no_channels):\n",
    "            bands_video.append(bandpower_multitaper(input_brainwaves[k,:], sf=frequency, method='multitaper',\n",
    "                                                    band=[0.5, 4], relative=False))\n",
    "            bands_video.append(bandpower_multitaper(input_brainwaves[k,:], sf=frequency, method='multitaper',\n",
    "                                                    band=[4, 7], relative=False))\n",
    "            bands_video.append(bandpower_multitaper(input_brainwaves[k,:], sf=frequency, method='multitaper',\n",
    "                                                    band=[8, 13], relative=False))\n",
    "            bands_video.append(bandpower_multitaper(input_brainwaves[k,:], sf=frequency, method='multitaper',\n",
    "                                                    band=[14, 30], relative=False))\n",
    "            bands_video.append(bandpower_multitaper(input_brainwaves[k,:], sf=frequency, method='multitaper',\n",
    "                                                    band=[31, 50], relative=False))\n",
    "            bands_video.append(bandpower_multitaper(input_brainwaves[k,:], sf=frequency, method='multitaper',\n",
    "                                                    band=[8, 40], relative=False))\n",
    "      \n",
    "        bandpower_multitaper_EEG.append(bands_video)\n",
    "\n",
    "    bandpower_multitaper_EEG = np.array(bandpower_multitaper_EEG)\n",
    "\n",
    "    return bandpower_multitaper_EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54170f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = 1000\n",
    "window = 1\n",
    "psd_features = []\n",
    "for x in X:\n",
    "    epoch = sliding_window(x, sf=sf, window=window, step=window)[1]\n",
    "    psd = create_bandpower_features(epoch, sf)\n",
    "    psd_features.append(psd)\n",
    "    print(len(psd_features))\n",
    "psd_features = np.array(psd_features)\n",
    "psd_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9ef78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "psd_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7da609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b479fc51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5b5bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8f52b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6b512c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013eda78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b55a69d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405202f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc47045a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
