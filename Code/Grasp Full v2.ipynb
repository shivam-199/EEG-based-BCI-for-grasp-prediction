{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e9c798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "from random import sample\n",
    "\n",
    "from scipy.io import wavfile, savemat\n",
    "from scipy.fft import fft, fftfreq\n",
    "from scipy import signal\n",
    "from scipy.fft import fftshift\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import librosa\n",
    "import mne\n",
    "import pymatreader\n",
    "import yasa\n",
    "import seaborn as sns\n",
    "import pyxdf\n",
    "\n",
    "from mne.time_frequency import psd_array_multitaper\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from mne.decoding import CSP\n",
    "from scipy.integrate import simps\n",
    "from yasa import sliding_window\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "from autoreject import AutoReject\n",
    " \n",
    "# %matplotlib qt\n",
    "\n",
    "%matplotlib inline\n",
    "import plotly.io as pio\n",
    "pio.renderers.default='notebook'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e753f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from EEGModels import EEGNet, ShallowConvNet, DeepConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bafe430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac849e63",
   "metadata": {},
   "source": [
    "# Loading raw data and preprocessing it using MNE-python [Use EEGLAB instead]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2285d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess_Raw_EEG:\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Data constants\n",
    "        self.sf = 1000\n",
    "        self.nchan = 64\n",
    "        self.ch_type = \"eeg\"\n",
    "        self.channels = [f'E{n:1}' for n in range(1, self.nchan+1)]\n",
    "        \n",
    "        #Preprocessing constants\n",
    "        self.low_pass = 40\n",
    "        self.high_pass = 1\n",
    "        self.notch = 50\n",
    "        self.target_sf = 1000\n",
    "        \n",
    "        # Path Constants\n",
    "        self.raw_eeg_path = \"/mnt/sda1/shivam/Thesis/Grasp Experiment/Data/Raw\"\n",
    "        self.chanloc_path = \"/mnt/sda1/shivam/Thesis/Grasp Experiment/Data/ChannelLocations/EGIAmpServer64Chan.loc\"\n",
    "    \n",
    "    def create_info(self):\n",
    "        chans = mne.channels.read_custom_montage(self.chanloc_path)\n",
    "        info = mne.create_info(channels, sfreq=self.sf, ch_types=self.ch_type)\n",
    "        info.set_montage(chans)\n",
    "        return info\n",
    "    \n",
    "    def create_events(self, stream):\n",
    "        event_id_dict = {}\n",
    "        ctr = 0\n",
    "        events = stream[0][1][\"time_series\"]\n",
    "        for mark in events:\n",
    "            if mark[0] not in event_id_dict:\n",
    "                if \"ActionBeg\" in mark[0]:\n",
    "                    event_id_dict[mark[0]] = ctr\n",
    "                    ctr += 1\n",
    "        \n",
    "        # creating array for epoching\n",
    "        events = []\n",
    "        time_stamps = stream[0][1][\"time_stamps\"]\n",
    "        event_name = stream[0][1][\"time_series\"]\n",
    "        event_name[0]\n",
    "        for i in range(len(time_stamps)):\n",
    "            if \"ActionBeg\" in event_name[i][0]:\n",
    "                row = []\n",
    "                row.append(int(time_stamps[i]))\n",
    "                row.append(int(0))\n",
    "                row.append(event_id_dict[event_name[i][0]])\n",
    "                events.append(np.array(row))\n",
    "\n",
    "        events = np.array(events)\n",
    "        \n",
    "        return event_id_dict, events\n",
    "    \n",
    "    def preprocess_data(self, stream):\n",
    "        \n",
    "        eeg_data = stream[0][0][\"time_series\"].T\n",
    "        \n",
    "        raw = mne.io.RawArray(eeg_data, self.create_info())\n",
    "        \n",
    "        # Filtering\n",
    "        raw.filter(float(self.low_pass), float(self.high_pass), fir_design='firwin')\n",
    "        raw.notch_filter(float(self.notch), method='fft')\n",
    "        \n",
    "        # Clean artifacts using ICA: remove 0, 1, and 2 independent components\n",
    "        filt_raw = raw.copy()\n",
    "        ica = ICA(n_components=10, max_iter='auto', random_state=97)\n",
    "        ica.fit(filt_raw)\n",
    "#         ica.exclude = [0, 1, 2]\n",
    "        \n",
    "        reconst_raw = raw.copy()\n",
    "        ica.apply(reconst_raw)\n",
    "        \n",
    "        # Spherical Interpolation\n",
    "        interp_raw = reconst_raw.copy().interpolate_bads(\n",
    "            reset_bads=False, method=dict(eeg='MNE'), verbose=True\n",
    "        )        \n",
    "        \n",
    "        # Re-referencing\n",
    "        reref_raw = interp_raw.copy().set_eeg_reference(ref_channels='average')\n",
    "        times_baseline_corr = np.array(reref_raw.to_data_frame().iloc[:, 0])\n",
    "        \n",
    "        # Creating epochs in the data and applying baseline correction trial-wise\n",
    "        event_id_dict, events = self.create_events(stream)\n",
    "        epochs = mne.Epochs(reref_raw, events, event_id = event_id_dict, tmin=-0.1, tmax=1.0)\n",
    "\n",
    "        return epochs\n",
    "    \n",
    "    def get_ica_activations(self, stream):\n",
    "        eeg_data = stream[0][0][\"time_series\"].T\n",
    "        raw = mne.io.RawArray(eeg_data, self.create_info())\n",
    "        \n",
    "        # Filtering\n",
    "        raw.filter(float(self.low_pass), float(self.high_pass), fir_design='firwin')\n",
    "        raw.notch_filter(float(self.notch), method='fft')\n",
    "        \n",
    "        # Get ICA components and sphere\n",
    "        filt_raw = raw.copy()\n",
    "        ica = ICA(n_components=10, max_iter='auto', random_state=97)\n",
    "        ica.fit(filt_raw)\n",
    "        \n",
    "        ica_act = np.matmul() ica.get_components() * ica.unmixing_matrix_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a85868",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preprocess = Preprocess_Raw_EEG()\n",
    "\n",
    "# Loading Raw EEG data\n",
    "temp_file = \"P02.xdf\"\n",
    "stream = pyxdf.load_xdf(temp_file)\n",
    "\n",
    "# Preprocessing\n",
    "clean_epochs = preprocess.preprocess_data(stream)\n",
    "clean_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ddab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path = \"/mnt/sda1/shivam/Thesis/Grasp Experiment/Data/Raw\"\n",
    "os.chdir(raw_path)\n",
    "\n",
    "all_clean_epochs = []\n",
    "\n",
    "for file in glob.glob(\"*.xdf\"):\n",
    "    print(\"##### \", file, \"#####\")\n",
    "    \n",
    "    # Reading raw eeg files using mne\n",
    "    stream = pyxdf.load_xdf(file)\n",
    "    \n",
    "    # Preprocessing\n",
    "    clean_epochs = preprocess.preprocess_data(stream)\n",
    "    all_clean_epochs.append(clean_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44f57dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_clean_epochs[0].to_data_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d95ec67",
   "metadata": {},
   "source": [
    "# Independent Components for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39d4b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7159a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action_events(events):\n",
    "    new_keys_dict = {}\n",
    "    for key in events[1].keys():\n",
    "        if \"ActionBeg\" in key:\n",
    "            new_keys_dict[key] = events[1][key]\n",
    "    new_event_times = [row for row in events[0] if row[2] in new_keys_dict.values()] \n",
    "    return (new_event_times, new_keys_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbae89bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/mnt/sda1/shivam/Thesis/Grasp Experiment/Data/PreprocessedData/ICs/\")\n",
    "print(\"Current directory: \", os.getcwd())\n",
    "data_files = glob.glob(\"*.set\")\n",
    "\n",
    "eeg_df_main = pd.DataFrame()\n",
    "\n",
    "for file_name in data_files:\n",
    "    # Reading the set file\n",
    "    print(\"Current file: \", file_name)\n",
    "    arr = mne.io.read_raw_eeglab(file_name, verbose=0)\n",
    "    eeg_data = arr.to_data_frame()\n",
    "    events = mne.events_from_annotations(arr, verbose=0)\n",
    "    \n",
    "    # Extracting events of interest\n",
    "    new_events = get_action_events(events)\n",
    "    \n",
    "    # Creating epochs\n",
    "    epochs = mne.Epochs(arr, new_events[0], event_id=new_events[1], tmin=-0.1, tmax=1.0,  baseline=None, verbose=0)\n",
    "    epoch_df = epochs.to_data_frame()\n",
    "    \n",
    "    # Transforming epoch dataframe to dataframe of interets\n",
    "    all_epochs_df = pd.DataFrame()\n",
    "    ctr = 1\n",
    "    for n_epoch in range(n_epochs):\n",
    "        eeg_only = epoch_df[epoch_df[\"epoch\"] == n_epoch].reset_index().iloc[:, 4:].T\n",
    "        label = epoch_df[epoch_df[\"epoch\"] == n_epoch][\"condition\"].iloc[0]\n",
    "        eeg_only[\"HandPos\"] = label.split(\"-\")[1]\n",
    "        eeg_only[\"Hand\"] = label.split(\"-\")[2]\n",
    "        eeg_only[\"Action\"] = label.split(\"-\")[3]\n",
    "        eeg_only[\"Subject\"] = file_name.split(\".\")[0]\n",
    "        eeg_only[\"Component\"] = [x[1:] for x in eeg_only.index]\n",
    "        eeg_only[\"Trial\"] = ctr\n",
    "        eeg_only.reset_index()\n",
    "        ctr += 1\n",
    "\n",
    "        all_epochs_df = pd.concat([all_epochs_df, eeg_only])\n",
    "        \n",
    "    eeg_df_main = pd.concat([eeg_df_main, all_epochs_df])\n",
    "    print(eeg_df_main.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba76e6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/mnt/sda1/shivam/Thesis/Grasp Experiment/Data/CleanSep/\")\n",
    "eeg_df_main.to_csv(\"ICs_v1.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0118672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8f9be19",
   "metadata": {},
   "source": [
    "# Subject-wise classification based on independentcomponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647232c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/mnt/sda1/shivam/Thesis/Grasp Experiment/Data/CleanSep/\")\n",
    "dataset = pd.read_csv(\"ICs_v1.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88819ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = \"P02\"\n",
    "dataset[dataset[\"Subject\"] == sub]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4ae257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source : https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
    "\n",
    "clfs = [\n",
    "    KNeighborsClassifier(2, n_jobs=-1),\n",
    "    # SVC(kernel=\"linear\", C=0.025),\n",
    "#     SVC(gamma=2, C=1),\n",
    "    # GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=2000),\n",
    "    RandomForestClassifier(max_depth=2000, n_estimators=100, max_features=1, n_jobs=-1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()\n",
    "]\n",
    "\n",
    "names = [\n",
    "    \"KNN\",\n",
    "    # \"Linear SVM\",\n",
    "#     \"RBF SVM\",\n",
    "    # \"Gaussian Process\",\n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "    \"Neural Net\",\n",
    "    \"AdaBoost\",\n",
    "    \"Naive Bayes\",\n",
    "    \"QDA\",\n",
    "]\n",
    "\n",
    "clfs_mlp = [\n",
    "    MLPClassifier(hidden_layer_sizes=(10, 20, 10), alpha=0.01, max_iter=1000),\n",
    "    MLPClassifier(hidden_layer_sizes=(20, 40, 30), alpha=0.01, max_iter=1000),\n",
    "    MLPClassifier(hidden_layer_sizes=(30, 60, 45), alpha=0.01, max_iter=1000),\n",
    "    MLPClassifier(hidden_layer_sizes=(40, 80, 60), alpha=0.01, max_iter=1000),\n",
    "    MLPClassifier(hidden_layer_sizes=(60, 120, 80), alpha=0.01, max_iter=1000),\n",
    "    MLPClassifier(hidden_layer_sizes=(80, 140, 100), alpha=0.01, max_iter=1000),\n",
    "]\n",
    "\n",
    "names_mlp = [\n",
    "    \"MLP1\",\n",
    "    \"MLP2\",\n",
    "    \"MLP3\",\n",
    "    \"MLP4\",\n",
    "    \"MLP5\",\n",
    "    \"MLP6\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fe4a7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# subject-wise classification using different components one at a time\n",
    "grasp_dict = {\"Open\": 0, \"Close\": 1}\n",
    "sub = \"P02\"\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for comp in range(1, 65):\n",
    "    print(\"### Component \", comp, \"###\")\n",
    "    X, y = [], []\n",
    "    comp_data = dataset[(dataset[\"Component\"] == comp) & (dataset[\"Subject\"] == sub)]\n",
    "    for trial in range(1, len(np.unique(dataset[\"Trial\"]))+1 ):\n",
    "        X.append(comp_data[comp_data[\"Trial\"] == trial].iloc[0, :-6].to_numpy())\n",
    "        y.append(grasp_dict[comp_data[comp_data[\"Trial\"] == trial].iloc[:, -4].to_numpy()[0]])\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    \n",
    "    results_comp = []\n",
    "    for idx,clf in enumerate(clfs):\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        results_comp.append([comp, names[idx], score])\n",
    "        print(names[idx], score)\n",
    "    \n",
    "    print()\n",
    "    all_results += results_comp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dc4b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pp = []\n",
    "for res in all_results:\n",
    "    results_pp += res\n",
    "results_pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40851369",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results_pp, columns=[\"Component\", \"Classifier\", \"Accuracy\"])\n",
    "os.chdir(\"/mnt/sda1/shivam/Thesis/Grasp Experiment/Data/Results/v3/\")\n",
    "results_df.to_csv(\"P02-ML-all-Comp.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455cc1aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e16f2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = np.unique(dataset[\"Subject\"])\n",
    "trial = np.unique(dataset[dataset[\"Subject\"] == \"FP02\"][\"Trial\"])\n",
    "subjects, trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3259a1f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Subject-wise and component-wise classification using Machine Learning\n",
    "\n",
    "grasp_dict = {\"Open\": 0, \"Close\": 1}\n",
    "\n",
    "comp_results = []\n",
    "for comp in range(1, 65):\n",
    "    print(\"### Component \", comp, \"###\")\n",
    "    \n",
    "    sub_results = []\n",
    "    for sub in subjects:\n",
    "        print(\"\\t ### Subject \", sub, \"###\")\n",
    "        trials = np.unique(dataset[dataset[\"Subject\"] == sub][\"Trial\"])\n",
    "        \n",
    "        X, y = [], []\n",
    "        for trial in trials:\n",
    "            pc_eeg = dataset[\n",
    "                (dataset[\"Subject\"] == sub) & \n",
    "                (dataset[\"Component\"] == comp) & \n",
    "                (dataset[\"Trial\"] == trial)\n",
    "            ]\n",
    "            # print(pc_eeg.to_numpy()[0].shape)\n",
    "            X.append(pc_eeg.iloc[0, :-6].to_numpy())\n",
    "            y.append(grasp_dict[pc_eeg.iloc[:, -4].to_numpy()[0]])\n",
    "\n",
    "        X, y = np.array(X), np.array(y)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "        results_comp = []\n",
    "        for idx,clf in enumerate(clfs):\n",
    "            clf.fit(X_train, y_train)\n",
    "            score = clf.score(X_test, y_test)\n",
    "            results_comp.append([comp, sub, names[idx], score])\n",
    "            print(\"\\t\", names[idx], score)\n",
    "\n",
    "        print()\n",
    "        sub_results += results_comp\n",
    "    comp_results += sub_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4051f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_wise_res_df = pd.DataFrame(comp_results, columns=[\"Component\", \"Subject\", \"Classifier\", \"Accuracy\"])\n",
    "os.chdir(\"/mnt/sda1/shivam/Thesis/Grasp Experiment/Data/Results/v3/\")\n",
    "subject_wise_res_df.to_csv(\"AllSub-ML-AllComp.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bea81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad_participants = [\"FP01\", \"FP10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9a7569",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6c9b33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Subject-wise and component-wise classification using EEGNET\n",
    "\n",
    "grasp_dict = {\"Open\": 0, \"Close\": 1}\n",
    "subjects = np.unique(dataset[\"Subject\"])\n",
    "\n",
    "sub_results = []\n",
    "best_models = []\n",
    "for sub in subjects:\n",
    "    print(\"\\t ### Subject \", sub, \"###\")\n",
    "    trials = np.unique(dataset[dataset[\"Subject\"] == sub][\"Trial\"])\n",
    "\n",
    "    X, y = [], []\n",
    "    for trial in trials:\n",
    "        pc_eeg = dataset[(dataset[\"Subject\"] == sub) & (dataset[\"Trial\"] == trial)]\n",
    "        \n",
    "        X.append(pc_eeg.iloc[:, :-6].to_numpy())\n",
    "        y.append(grasp_dict[pc_eeg.iloc[:, -4].to_numpy()[0]])\n",
    "\n",
    "    X, y = np.array(X, dtype=np.float32), np.array(y)\n",
    "\n",
    "    X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "    checkpoint_filepath = \"/tmp/checkpoint/\"\n",
    "    checkpointer = ModelCheckpoint(\n",
    "            filepath=checkpoint_filepath, \n",
    "            save_weights_only=True,\n",
    "            monitor=\"val_accuracy\",\n",
    "            mode=\"max\",\n",
    "            save_best_only=True\n",
    "    )\n",
    "\n",
    "    modelEEGNET = EEGNet(nb_classes = 2, Chans = 64, Samples = 1101)\n",
    "    modelEEGNET.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
    "    fittedModel = modelEEGNET.fit(\n",
    "        X_train, y_train, epochs=100, batch_size=128, validation_data=(X_eval, y_eval), \n",
    "        callbacks=[checkpointer], verbose=None\n",
    "    )\n",
    "\n",
    "    modelEEGNET.load_weights(checkpoint_filepath)\n",
    "    y_pred = np.argmax(modelEEGNET.predict(X_test), axis=1)\n",
    "\n",
    "    y_true = y_test\n",
    "    test_acc = sum(y_pred == y_true) / len(y_true)\n",
    "    print(\"Test accuracy: \", test_acc)\n",
    "\n",
    "    sub_results += [sub, test_acc]\n",
    "    best_models.append(modelEEGNET)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04884950",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.reshape(sub_results, (15, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a8eaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_wise_res_eegnet_df = pd.DataFrame(np.reshape(sub_results, (15, 2)), columns=[\"Subject\", \"Accuracy\"])\n",
    "os.chdir(\"/mnt/sda1/shivam/Thesis/Grasp Experiment/Data/Results/v3/\")\n",
    "subject_wise_res_eegnet_df.to_csv(\"AllSub-EEGNET-AllComp.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492b61c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_wise_res_eegnet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e91642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b350ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae078676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f566f57d",
   "metadata": {},
   "source": [
    "# Model Agnostic Meta Learning using Indepenent Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf148e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023ee899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb947df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cfaf5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8530d32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed686dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f1f4ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672779d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0e2dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f65011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccdc497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b9f88e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb15230f",
   "metadata": {},
   "source": [
    "# All subject classification using different components one at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c8cb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/mnt/sda1/shivam/Thesis/Grasp Experiment/Data/CleanSep/\")\n",
    "dataset = pd.read_csv(\"ICs_v1.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad864559",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grasp_dict = {\"Open\": 0, \"Close\": 1}\n",
    "\n",
    "comp_res = []\n",
    "for comp in range(1, 65):\n",
    "    X, y = [], []\n",
    "    print(\"Component \", comp)\n",
    "    for sub in subjects:\n",
    "        comp_data = dataset[(dataset[\"Component\"] == comp) & (dataset[\"Subject\"] == sub)]\n",
    "        for trial in range(1, len(np.unique(dataset[\"Trial\"]))+1 ):\n",
    "            X.append(comp_data[comp_data[\"Trial\"] == trial].iloc[0, :-6].to_numpy())\n",
    "            y.append(grasp_dict[comp_data[comp_data[\"Trial\"] == trial].iloc[:, -4].to_numpy()[0]])\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "    results = []\n",
    "    for idx,clf in enumerate(clfs):\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        results.append([comp, names[idx], score])\n",
    "        print(names[idx], score)\n",
    "    \n",
    "    comp_res += results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eebd509",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_wise_res_df = pd.DataFrame(comp_res, columns=[\"Component\", \"Classifier\", \"Accuracy\"])\n",
    "os.chdir(\"/mnt/sda1/shivam/Thesis/Grasp Experiment/Data/Results/v3/\")\n",
    "comp_wise_res_df.to_csv(\"Component-wise-Allsub.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ef6696",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/shivam/Desktop\")\n",
    "comp_wise_res_df.to_csv(\"Component-wise-Allsub.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa571598",
   "metadata": {},
   "source": [
    "# Cross-subject classification using IC Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618c26bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdf6176",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cbd10c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca9a323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacb7774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff493e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8432b91f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82c0387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50d8573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d81a83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b168d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d212fa42",
   "metadata": {},
   "source": [
    "# PSD Classification using entire band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69da473b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action_events(events):\n",
    "    new_keys_dict = {}\n",
    "    for key in events[1].keys():\n",
    "        if \"ActionBeg\" in key:\n",
    "            new_keys_dict[key] = events[1][key]\n",
    "    new_event_times = [row for row in events[0] if row[2] in new_keys_dict.values()] \n",
    "    return (new_event_times, new_keys_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d1a89f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/mnt/sda1/shivam/Thesis/Grasp Experiment/Data/PreprocessedData/Preprocessed ICA/\")\n",
    "print(\"Current directory: \", os.getcwd())\n",
    "data_files = glob.glob(\"*.set\")\n",
    "\n",
    "eeg_df_main = pd.DataFrame()\n",
    "\n",
    "for file_name in data_files:\n",
    "    # Reading the set file\n",
    "    print(\"Current file: \", file_name)\n",
    "    arr = mne.io.read_raw_eeglab(file_name, verbose=0)\n",
    "    eeg_data = arr.to_data_frame()\n",
    "    events = mne.events_from_annotations(arr, verbose=0)\n",
    "    \n",
    "    # Extracting events of interest\n",
    "    new_events = get_action_events(events)\n",
    "    \n",
    "    # Creating epochs\n",
    "    epochs = mne.Epochs(arr, new_events[0], event_id=new_events[1], tmin=-0.1, tmax=1.0,  baseline=None, verbose=0)\n",
    "    epoch_df = epochs.to_data_frame()\n",
    "    \n",
    "    n_epochs = len(epochs)\n",
    "    \n",
    "    # Transforming epoch dataframe to dataframe of interets\n",
    "    all_epochs_df = pd.DataFrame()\n",
    "    ctr = 1\n",
    "    for n_epoch in range(n_epochs):\n",
    "        eeg_only = epoch_df[epoch_df[\"epoch\"] == n_epoch].reset_index().iloc[:, 4:].T\n",
    "        label = epoch_df[epoch_df[\"epoch\"] == n_epoch][\"condition\"].iloc[0]\n",
    "        eeg_only[\"HandPos\"] = label.split(\"-\")[1]\n",
    "        eeg_only[\"Hand\"] = label.split(\"-\")[2]\n",
    "        eeg_only[\"Action\"] = label.split(\"-\")[3]\n",
    "        eeg_only[\"Subject\"] = file_name.split(\".\")[0]\n",
    "        eeg_only[\"Component\"] = [x[1:] for x in eeg_only.index]\n",
    "        eeg_only[\"Trial\"] = ctr\n",
    "        eeg_only.reset_index()\n",
    "        ctr += 1\n",
    "\n",
    "        all_epochs_df = pd.concat([all_epochs_df, eeg_only])\n",
    "        \n",
    "    eeg_df_main = pd.concat([eeg_df_main, all_epochs_df])\n",
    "    print(eeg_df_main.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472a69d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/mnt/sda1/shivam/Thesis/Grasp Experiment/Data/CleanSep/\")\n",
    "eeg_df_main.to_csv(\"CLeanICAV1.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa833296",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"/mnt/sda1/shivam/Thesis/Grasp Experiment/Data/CleanSep/CLeanICAV1.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dd561d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 64 channel EEG data with 500 samples\n",
    "# Giving us X = N * 64 * 275 and y = N \n",
    "X, y = [], []\n",
    "grasp_labels = {\"Open\": 0, \"Close\": 1}\n",
    "nchan = 64\n",
    "iterations = len(dataset) // nchan\n",
    "for idx in range(iterations):\n",
    "    start = idx * nchan\n",
    "    end = (idx + 1) * nchan\n",
    "\n",
    "    X.append(dataset.iloc[start: end, :1001])\n",
    "    y.append(grasp_labels[dataset.iloc[start, -4]])\n",
    "\n",
    "    \n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b912d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multitaper method\n",
    "def bandpower_multitaper(data, sf, method, band, relative=False):\n",
    "    band = np.asarray(band)\n",
    "    low, high = band\n",
    "\n",
    "    if method == 'multitaper':\n",
    "        psd_trial, freqs = psd_array_multitaper(data, sf, adaptive=True,\n",
    "                                                normalization='full', verbose=0)\n",
    "    # Frequency resolution\n",
    "    freq_res = freqs[1] - freqs[0]\n",
    "\n",
    "    # Find index of band in frequency vector\n",
    "    idx_band = np.logical_and(freqs >= low, freqs <= high)\n",
    "\n",
    "    # Integral approximation of the spectrum using parabola (Simpson's rule)\n",
    "    bp = simps(psd_trial[idx_band], dx=freq_res)\n",
    "\n",
    "    return bp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ede3cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bandpower_features(epochs, frequency):\n",
    "    bandpower_multitaper_EEG = []\n",
    "    # Iterating over each subject [20]\n",
    "    for epoch in epochs:\n",
    "        # Iterating over each song per subject [30]\n",
    "        bands_video = []\n",
    "        no_channels = epoch.shape[0]\n",
    "        input_brainwaves = epoch\n",
    "        # Iterating over each channel [14]\n",
    "        for k in range(no_channels):\n",
    "            bands_video.append(bandpower_multitaper(input_brainwaves[k,:], sf=frequency, method='multitaper',\n",
    "                                                    band=[8, 30], relative=False)) # Alpha and Beta frequency bands\n",
    "#             bands_video.append(bandpower_multitaper(input_brainwaves[k,:], sf=frequency, method='multitaper',\n",
    "#                                                     band=[4, 7], relative=False))\n",
    "#             bands_video.append(bandpower_multitaper(input_brainwaves[k,:], sf=frequency, method='multitaper',\n",
    "#                                                     band=[8, 13], relative=False))\n",
    "#             bands_video.append(bandpower_multitaper(input_brainwaves[k,:], sf=frequency, method='multitaper',\n",
    "#                                                     band=[14, 30], relative=False))\n",
    "#             bands_video.append(bandpower_multitaper(input_brainwaves[k,:], sf=frequency, method='multitaper',\n",
    "#                                                     band=[31, 50], relative=False))\n",
    "      \n",
    "        bandpower_multitaper_EEG.append(bands_video)\n",
    "\n",
    "    bandpower_multitaper_EEG = np.array(bandpower_multitaper_EEG)\n",
    "  \n",
    "    return bandpower_multitaper_EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1036f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = 1000\n",
    "window = 1\n",
    "psd_features = []\n",
    "for x in X:\n",
    "    epoch = sliding_window(x, sf=sf, window=window, step=window)[1]\n",
    "    psd = create_bandpower_features(epoch, sf)\n",
    "    if len(psd_features) == 0:\n",
    "        psd_features = psd\n",
    "    else:\n",
    "        psd_features = np.concatenate((psd_features, psd))\n",
    "    print(psd_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd910386",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(psd_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afa7ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/mnt/sda1/shivam/Thesis/Grasp Experiment/Data/IntData/')\n",
    "np.save(\"pds_broadband_features.npy\", psd_features)\n",
    "np.save(\"pds_broadband_labels.npy\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03eea06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('/mnt/sda1/shivam/Thesis/Grasp Experiment/Data/IntData/')\n",
    "# psd_labels = []\n",
    "# for label in y:\n",
    "#     psd_labels += [label] * 1\n",
    "# np.save(\"pds_broadband_labels.npy\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09eeb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/mnt/sda1/shivam/Thesis/Grasp Experiment/Data/IntData/')\n",
    "X, y = np.load(\"pds_broadband_features.npy\"), np.load(\"pds_broadband_labels.npy\")\n",
    "X.shape, y.shape # ((1920, 320), (1920,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0a1ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# Take first 5 components using PCA \n",
    "pca = PCA(n_components=5)\n",
    "X_r = pca.fit(X).transform(X)\n",
    "X_r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fff3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_r, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e98cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source : https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
    "\n",
    "clfs = [\n",
    "    KNeighborsClassifier(2),\n",
    "    DecisionTreeClassifier(max_depth=2000),\n",
    "    RandomForestClassifier(max_depth=2000, n_estimators=200, max_features=\"auto\"),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()\n",
    "]\n",
    "\n",
    "names = [\n",
    "    \"Nearest Neighbors\",\n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "    \"Neural Net\",\n",
    "    \"AdaBoost\",\n",
    "    \"Naive Bayes\",\n",
    "    \"QDA\",\n",
    "]\n",
    "\n",
    "clfs_mlp = [\n",
    "    MLPClassifier(hidden_layer_sizes=(10, 20, 10), alpha=0.01, max_iter=1000),\n",
    "    MLPClassifier(hidden_layer_sizes=(20, 40, 30), alpha=0.01, max_iter=1000),\n",
    "    MLPClassifier(hidden_layer_sizes=(30, 60, 45), alpha=0.01, max_iter=1000),\n",
    "    MLPClassifier(hidden_layer_sizes=(40, 80, 60), alpha=0.01, max_iter=1000),\n",
    "    MLPClassifier(hidden_layer_sizes=(60, 120, 80), alpha=0.01, max_iter=1000),\n",
    "    MLPClassifier(hidden_layer_sizes=(80, 140, 100), alpha=0.01, max_iter=1000),\n",
    "]\n",
    "\n",
    "names_mlp = [\n",
    "    \"MLP1\",\n",
    "    \"MLP2\",\n",
    "    \"MLP3\",\n",
    "    \"MLP4\",\n",
    "    \"MLP5\",\n",
    "    \"MLP6\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e3d94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for idx,clf in enumerate(clfs_mlp):\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    results.append([names_mlp[idx], score])\n",
    "    print(names_mlp[idx], score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b70dbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Something's wrong above ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
